{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-09-28T14:35:42.966937Z",
     "iopub.status.busy": "2021-09-28T14:35:42.966127Z",
     "iopub.status.idle": "2021-09-28T14:35:44.092678Z",
     "shell.execute_reply": "2021-09-28T14:35:44.091833Z",
     "shell.execute_reply.started": "2021-09-28T13:39:14.900617Z"
    },
    "papermill": {
     "duration": 1.151354,
     "end_time": "2021-09-28T14:35:44.092911",
     "exception": false,
     "start_time": "2021-09-28T14:35:42.941557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# git clone package:\n",
    "# !git clone <path_package>\n",
    "# or copy package :\n",
    "!cp -r /kaggle/input/autonlp-git/SentimentML-main /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T14:35:44.134681Z",
     "iopub.status.busy": "2021-09-28T14:35:44.133892Z",
     "iopub.status.idle": "2021-09-28T14:35:44.138174Z",
     "shell.execute_reply": "2021-09-28T14:35:44.137674Z",
     "shell.execute_reply.started": "2021-09-28T13:39:16.015875Z"
    },
    "papermill": {
     "duration": 0.028451,
     "end_time": "2021-09-28T14:35:44.138314",
     "exception": false,
     "start_time": "2021-09-28T14:35:44.109863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/SentimentML-main'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# directory of package :\n",
    "fd = os.open(\"/kaggle/working/SentimentML-main\", os.O_RDONLY )\n",
    "os.fchdir(fd)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-09-28T14:35:44.182157Z",
     "iopub.status.busy": "2021-09-28T14:35:44.177696Z",
     "iopub.status.idle": "2021-09-28T14:37:48.231797Z",
     "shell.execute_reply": "2021-09-28T14:37:48.232266Z",
     "shell.execute_reply.started": "2021-09-28T13:39:16.02797Z"
    },
    "papermill": {
     "duration": 124.076926,
     "end_time": "2021-09-28T14:37:48.232485",
     "exception": false,
     "start_time": "2021-09-28T14:35:44.155559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests==2.25.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (2.25.1)\r\n",
      "Collecting textblob_fr==0.2.0\r\n",
      "  Downloading textblob_fr-0.2.0-py2.py3-none-any.whl (561 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 561 kB 287 kB/s \r\n",
      "\u001b[?25hCollecting streamlit==0.83.0\r\n",
      "  Downloading streamlit-0.83.0-py2.py3-none-any.whl (7.7 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 7.7 MB 6.2 MB/s \r\n",
      "\u001b[?25hCollecting pytest==6.2.5\r\n",
      "  Downloading pytest-6.2.5-py3-none-any.whl (280 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 280 kB 67.0 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: dataclasses==0.6 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (0.6)\r\n",
      "Collecting matplotlib==3.3.2\r\n",
      "  Downloading matplotlib-3.3.2-cp37-cp37m-manylinux1_x86_64.whl (11.6 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 11.6 MB 67.2 MB/s \r\n",
      "\u001b[?25hCollecting sentence_transformers==2.0.0\r\n",
      "  Downloading sentence-transformers-2.0.0.tar.gz (85 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 85 kB 4.1 MB/s \r\n",
      "\u001b[?25hCollecting umap_learn==0.5.1\r\n",
      "  Downloading umap-learn-0.5.1.tar.gz (80 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 80 kB 6.8 MB/s \r\n",
      "\u001b[?25hCollecting gensim==4.0.1\r\n",
      "  Downloading gensim-4.0.1-cp37-cp37m-manylinux1_x86_64.whl (23.9 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 23.9 MB 1.0 MB/s \r\n",
      "\u001b[?25hCollecting transformers==4.9.0\r\n",
      "  Downloading transformers-4.9.0-py3-none-any.whl (2.6 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 2.6 MB 71.1 MB/s \r\n",
      "\u001b[?25hCollecting seaborn==0.11.0\r\n",
      "  Downloading seaborn-0.11.0-py3-none-any.whl (283 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 283 kB 65.5 MB/s \r\n",
      "\u001b[?25hCollecting tqdm==4.50.2\r\n",
      "  Downloading tqdm-4.50.2-py2.py3-none-any.whl (70 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 70 kB 7.9 MB/s \r\n",
      "\u001b[?25hCollecting pandas==1.3.0\r\n",
      "  Downloading pandas-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (10.8 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 10.8 MB 66.5 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: textblob==0.15.3 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 14)) (0.15.3)\r\n",
      "Collecting joblib==0.17.0\r\n",
      "  Downloading joblib-0.17.0-py3-none-any.whl (301 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 301 kB 53.6 MB/s \r\n",
      "\u001b[?25hCollecting xgboost==1.4.2\r\n",
      "  Downloading xgboost-1.4.2-py3-none-manylinux2010_x86_64.whl (166.7 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 166.7 MB 16 kB/s \r\n",
      "\u001b[?25hCollecting uvicorn==0.13.4\r\n",
      "  Downloading uvicorn-0.13.4-py3-none-any.whl (46 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 46 kB 2.6 MB/s \r\n",
      "\u001b[?25hCollecting spacy==3.0.5\r\n",
      "  Downloading spacy-3.0.5-cp37-cp37m-manylinux2014_x86_64.whl (12.8 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 12.8 MB 39.4 MB/s \r\n",
      "\u001b[?25hCollecting tensorflow==2.4.1\r\n",
      "  Downloading tensorflow-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 394.3 MB 11 kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: wordcloud==1.8.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 20)) (1.8.1)\r\n",
      "Collecting ray==1.2.0\r\n",
      "  Downloading ray-1.2.0-cp37-cp37m-manylinux2014_x86_64.whl (47.5 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 47.5 MB 38 kB/s \r\n",
      "\u001b[?25hCollecting numpy==1.19.2\r\n",
      "  Downloading numpy-1.19.2-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 14.5 MB 22 kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: plotly==4.14.3 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 23)) (4.14.3)\r\n",
      "Collecting fastapi==0.68.1\r\n",
      "  Downloading fastapi-0.68.1-py3-none-any.whl (52 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 52 kB 733 kB/s \r\n",
      "\u001b[?25hCollecting ipython==7.27.0\r\n",
      "  Downloading ipython-7.27.0-py3-none-any.whl (787 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 787 kB 39.7 MB/s \r\n",
      "\u001b[?25hCollecting PyYAML==5.4.1\r\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 636 kB 53.1 MB/s \r\n",
      "\u001b[?25hCollecting scikit_learn==0.24.2\r\n",
      "  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 22.3 MB 1.1 MB/s \r\n",
      "\u001b[?25hCollecting umap==0.1.1\r\n",
      "  Downloading umap-0.1.1.tar.gz (3.2 kB)\r\n",
      "Collecting scipy==1.5.2\r\n",
      "  Downloading scipy-1.5.2-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 25.9 MB 792 kB/s \r\n",
      "\u001b[?25hCollecting tokenizers==0.10.3\r\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 60.3 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: sentencepiece==0.1.95 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 31)) (0.1.95)\r\n",
      "Collecting mlflow==1.17.0\r\n",
      "  Downloading mlflow-1.17.0-py3-none-any.whl (14.2 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 14.2 MB 39.7 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: hyperopt==0.2.5 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 33)) (0.2.5)\r\n",
      "Collecting raceplotly==0.1.6\r\n",
      "  Downloading raceplotly-0.1.6-py3-none-any.whl (7.2 kB)\r\n",
      "Collecting python-multipart==0.0.5\r\n",
      "  Downloading python-multipart-0.0.5.tar.gz (32 kB)\r\n",
      "Collecting pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2\r\n",
      "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 10.1 MB 59.3 MB/s \r\n",
      "\u001b[?25hCollecting starlette==0.14.2\r\n",
      "  Downloading starlette-0.14.2-py3-none-any.whl (60 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 60 kB 7.1 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from gensim==4.0.1->-r requirements.txt (line 9)) (4.1.2)\r\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.7/site-packages (from hyperopt==0.2.5->-r requirements.txt (line 33)) (2.5)\r\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from hyperopt==0.2.5->-r requirements.txt (line 33)) (1.6.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from hyperopt==0.2.5->-r requirements.txt (line 33)) (1.15.0)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from hyperopt==0.2.5->-r requirements.txt (line 33)) (0.18.2)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython==7.27.0->-r requirements.txt (line 25)) (3.0.8)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython==7.27.0->-r requirements.txt (line 25)) (4.8.0)\r\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython==7.27.0->-r requirements.txt (line 25)) (0.2.0)\r\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython==7.27.0->-r requirements.txt (line 25)) (2.7.3)\r\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython==7.27.0->-r requirements.txt (line 25)) (49.6.0.post20201009)\r\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython==7.27.0->-r requirements.txt (line 25)) (0.7.5)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython==7.27.0->-r requirements.txt (line 25)) (0.18.0)\r\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipython==7.27.0->-r requirements.txt (line 25)) (5.0.5)\r\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython==7.27.0->-r requirements.txt (line 25)) (4.4.2)\r\n",
      "Collecting matplotlib-inline\r\n",
      "  Downloading matplotlib_inline-0.1.3-py3-none-any.whl (8.2 kB)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.3.2->-r requirements.txt (line 6)) (2.4.7)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.3.2->-r requirements.txt (line 6)) (0.10.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.3.2->-r requirements.txt (line 6)) (1.3.1)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.3.2->-r requirements.txt (line 6)) (7.2.0)\r\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.3.2->-r requirements.txt (line 6)) (2020.12.5)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.3.2->-r requirements.txt (line 6)) (2.8.1)\r\n",
      "Requirement already satisfied: sqlparse>=0.3.1 in /opt/conda/lib/python3.7/site-packages (from mlflow==1.17.0->-r requirements.txt (line 32)) (0.4.1)\r\n",
      "Requirement already satisfied: Flask in /opt/conda/lib/python3.7/site-packages (from mlflow==1.17.0->-r requirements.txt (line 32)) (1.1.2)\r\n",
      "Collecting databricks-cli>=0.8.7\r\n",
      "  Downloading databricks-cli-0.15.0.tar.gz (56 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 56 kB 3.6 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.7/site-packages (from mlflow==1.17.0->-r requirements.txt (line 32)) (7.1.2)\r\n",
      "Requirement already satisfied: docker>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from mlflow==1.17.0->-r requirements.txt (line 32)) (4.4.1)\r\n",
      "Requirement already satisfied: sqlalchemy in /opt/conda/lib/python3.7/site-packages (from mlflow==1.17.0->-r requirements.txt (line 32)) (1.3.22)\r\n",
      "Collecting prometheus-flask-exporter\r\n",
      "  Downloading prometheus_flask_exporter-0.18.2.tar.gz (22 kB)\r\n",
      "Collecting alembic<=1.4.1\r\n",
      "  Downloading alembic-1.4.1.tar.gz (1.1 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 61.3 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from mlflow==1.17.0->-r requirements.txt (line 32)) (3.14.0)\r\n",
      "Collecting gunicorn\r\n",
      "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 79 kB 7.1 MB/s \r\n",
      "\u001b[?25hCollecting querystring-parser\r\n",
      "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\r\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from mlflow==1.17.0->-r requirements.txt (line 32)) (2019.3)\r\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.7/site-packages (from mlflow==1.17.0->-r requirements.txt (line 32)) (0.3)\r\n",
      "Requirement already satisfied: gitpython>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from mlflow==1.17.0->-r requirements.txt (line 32)) (3.1.12)\r\n",
      "Requirement already satisfied: retrying>=1.3.3 in /opt/conda/lib/python3.7/site-packages (from plotly==4.14.3->-r requirements.txt (line 23)) (1.3.3)\r\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.7/site-packages (from pytest==6.2.5->-r requirements.txt (line 4)) (1.1.1)\r\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest==6.2.5->-r requirements.txt (line 4)) (3.3.0)\r\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest==6.2.5->-r requirements.txt (line 4)) (0.13.1)\r\n",
      "Requirement already satisfied: toml in /opt/conda/lib/python3.7/site-packages (from pytest==6.2.5->-r requirements.txt (line 4)) (0.10.2)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from pytest==6.2.5->-r requirements.txt (line 4)) (20.8)\r\n",
      "Requirement already satisfied: py>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from pytest==6.2.5->-r requirements.txt (line 4)) (1.10.0)\r\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.7/site-packages (from pytest==6.2.5->-r requirements.txt (line 4)) (20.3.0)\r\n",
      "Requirement already satisfied: aioredis in /opt/conda/lib/python3.7/site-packages (from ray==1.2.0->-r requirements.txt (line 21)) (1.3.1)\r\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from ray==1.2.0->-r requirements.txt (line 21)) (0.4.4)\r\n",
      "Requirement already satisfied: opencensus in /opt/conda/lib/python3.7/site-packages (from ray==1.2.0->-r requirements.txt (line 21)) (0.7.12)\r\n",
      "Requirement already satisfied: gpustat in /opt/conda/lib/python3.7/site-packages (from ray==1.2.0->-r requirements.txt (line 21)) (0.6.0)\r\n",
      "Requirement already satisfied: redis>=3.5.0 in /opt/conda/lib/python3.7/site-packages (from ray==1.2.0->-r requirements.txt (line 21)) (3.5.3)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from ray==1.2.0->-r requirements.txt (line 21)) (3.7.3)\r\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from ray==1.2.0->-r requirements.txt (line 21)) (1.0.2)\r\n",
      "Requirement already satisfied: aiohttp-cors in /opt/conda/lib/python3.7/site-packages (from ray==1.2.0->-r requirements.txt (line 21)) (0.7.0)\r\n",
      "Requirement already satisfied: grpcio>=1.28.1 in /opt/conda/lib/python3.7/site-packages (from ray==1.2.0->-r requirements.txt (line 21)) (1.32.0)\r\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.7/site-packages (from ray==1.2.0->-r requirements.txt (line 21)) (3.2.0)\r\n",
      "Requirement already satisfied: prometheus-client>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from ray==1.2.0->-r requirements.txt (line 21)) (0.9.0)\r\n",
      "Requirement already satisfied: colorful in /opt/conda/lib/python3.7/site-packages (from ray==1.2.0->-r requirements.txt (line 21)) (0.5.4)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from ray==1.2.0->-r requirements.txt (line 21)) (3.0.12)\r\n",
      "Requirement already satisfied: py-spy>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from ray==1.2.0->-r requirements.txt (line 21)) (0.3.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests==2.25.1->-r requirements.txt (line 1)) (1.26.2)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests==2.25.1->-r requirements.txt (line 1)) (2.10)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests==2.25.1->-r requirements.txt (line 1)) (3.0.4)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit_learn==0.24.2->-r requirements.txt (line 27)) (2.1.0)\r\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence_transformers==2.0.0->-r requirements.txt (line 7)) (1.7.0)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from sentence_transformers==2.0.0->-r requirements.txt (line 7)) (0.8.1)\r\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from sentence_transformers==2.0.0->-r requirements.txt (line 7)) (3.2.4)\r\n",
      "Collecting huggingface-hub\r\n",
      "  Downloading huggingface_hub-0.0.17-py3-none-any.whl (52 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 52 kB 1.2 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy==3.0.5->-r requirements.txt (line 18)) (0.7.4)\r\n",
      "Collecting typer<0.4.0,>=0.3.0\r\n",
      "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\r\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.0\r\n",
      "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\r\n",
      "Collecting srsly<3.0.0,>=2.4.0\r\n",
      "  Downloading srsly-2.4.1-cp37-cp37m-manylinux2014_x86_64.whl (456 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 456 kB 59.5 MB/s \r\n",
      "\u001b[?25hCollecting pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2\r\n",
      "  Downloading pydantic-1.7.4-cp37-cp37m-manylinux2014_x86_64.whl (9.1 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 9.1 MB 57.9 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: wasabi<1.1.0,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from spacy==3.0.5->-r requirements.txt (line 18)) (0.8.1)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy==3.0.5->-r requirements.txt (line 18)) (1.0.5)\r\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy==3.0.5->-r requirements.txt (line 18)) (3.7.4.3)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy==3.0.5->-r requirements.txt (line 18)) (2.0.5)\r\n",
      "Collecting thinc<8.1.0,>=8.0.2\r\n",
      "  Downloading thinc-8.0.10-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (623 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 623 kB 53.7 MB/s \r\n",
      "\u001b[?25hCollecting catalogue<2.1.0,>=2.0.1\r\n",
      "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\r\n",
      "Collecting pathy>=0.3.5\r\n",
      "  Downloading pathy-0.6.0-py3-none-any.whl (42 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 42 kB 979 kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy==3.0.5->-r requirements.txt (line 18)) (2.11.2)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy==3.0.5->-r requirements.txt (line 18)) (3.0.5)\r\n",
      "Collecting pydeck>=0.1.dev5\r\n",
      "  Downloading pydeck-0.7.0-py2.py3-none-any.whl (4.3 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 59.2 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: tzlocal in /opt/conda/lib/python3.7/site-packages (from streamlit==0.83.0->-r requirements.txt (line 3)) (2.1)\r\n",
      "Collecting astor\r\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\r\n",
      "Requirement already satisfied: altair>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from streamlit==0.83.0->-r requirements.txt (line 3)) (4.1.0)\r\n",
      "Requirement already satisfied: blinker in /opt/conda/lib/python3.7/site-packages (from streamlit==0.83.0->-r requirements.txt (line 3)) (1.4)\r\n",
      "Requirement already satisfied: watchdog in /opt/conda/lib/python3.7/site-packages (from streamlit==0.83.0->-r requirements.txt (line 3)) (0.10.4)\r\n",
      "Requirement already satisfied: cachetools>=4.0 in /opt/conda/lib/python3.7/site-packages (from streamlit==0.83.0->-r requirements.txt (line 3)) (4.1.1)\r\n",
      "Collecting base58\r\n",
      "  Downloading base58-2.1.0-py3-none-any.whl (5.6 kB)\r\n",
      "Collecting validators\r\n",
      "  Downloading validators-0.18.2-py3-none-any.whl (19 kB)\r\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.7/site-packages (from streamlit==0.83.0->-r requirements.txt (line 3)) (2.0.0)\r\n",
      "Requirement already satisfied: tornado>=5.0 in /opt/conda/lib/python3.7/site-packages (from streamlit==0.83.0->-r requirements.txt (line 3)) (5.0.2)\r\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1->-r requirements.txt (line 19)) (3.3.0)\r\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1->-r requirements.txt (line 19)) (1.1.0)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1->-r requirements.txt (line 19)) (2.4.0)\r\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1->-r requirements.txt (line 19)) (1.6.3)\r\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1->-r requirements.txt (line 19)) (1.1.2)\r\n",
      "Requirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1->-r requirements.txt (line 19)) (0.2.0)\r\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1->-r requirements.txt (line 19)) (1.12)\r\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1->-r requirements.txt (line 19)) (0.36.2)\r\n",
      "Requirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1->-r requirements.txt (line 19)) (0.10.0)\r\n",
      "Requirement already satisfied: gast==0.3.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1->-r requirements.txt (line 19)) (0.3.3)\r\n",
      "Requirement already satisfied: tensorboard~=2.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1->-r requirements.txt (line 19)) (2.4.1)\r\n",
      "Requirement already satisfied: h5py~=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1->-r requirements.txt (line 19)) (2.10.0)\r\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1->-r requirements.txt (line 19)) (1.12.1)\r\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers==4.9.0->-r requirements.txt (line 10)) (0.0.43)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.9.0->-r requirements.txt (line 10)) (2020.11.13)\r\n",
      "Collecting huggingface-hub\r\n",
      "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\r\n",
      "Requirement already satisfied: numba>=0.49 in /opt/conda/lib/python3.7/site-packages (from umap_learn==0.5.1->-r requirements.txt (line 8)) (0.52.0)\r\n",
      "Requirement already satisfied: pynndescent>=0.5 in /opt/conda/lib/python3.7/site-packages (from umap_learn==0.5.1->-r requirements.txt (line 8)) (0.5.1)\r\n",
      "Collecting h11>=0.8\r\n",
      "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 54 kB 2.6 MB/s \r\n",
      "\u001b[?25hCollecting packaging\r\n",
      "  Downloading packaging-21.0-py3-none-any.whl (40 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 40 kB 4.2 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: Mako in /opt/conda/lib/python3.7/site-packages (from alembic<=1.4.1->mlflow==1.17.0->-r requirements.txt (line 32)) (1.1.4)\r\n",
      "Requirement already satisfied: python-editor>=0.3 in /opt/conda/lib/python3.7/site-packages (from alembic<=1.4.1->mlflow==1.17.0->-r requirements.txt (line 32)) (1.0.4)\r\n",
      "Requirement already satisfied: toolz in /opt/conda/lib/python3.7/site-packages (from altair>=3.2.0->streamlit==0.83.0->-r requirements.txt (line 3)) (0.11.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.1->spacy==3.0.5->-r requirements.txt (line 18)) (3.4.0)\r\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /opt/conda/lib/python3.7/site-packages (from databricks-cli>=0.8.7->mlflow==1.17.0->-r requirements.txt (line 32)) (0.8.7)\r\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from docker>=4.0.0->mlflow==1.17.0->-r requirements.txt (line 32)) (0.57.0)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from gitpython>=2.1.0->mlflow==1.17.0->-r requirements.txt (line 32)) (4.0.5)\r\n",
      "Requirement already satisfied: smmap<4,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow==1.17.0->-r requirements.txt (line 32)) (3.0.4)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython==7.27.0->-r requirements.txt (line 25)) (0.8.1)\r\n",
      "Requirement already satisfied: llvmlite<0.36,>=0.35.0 in /opt/conda/lib/python3.7/site-packages (from numba>=0.49->umap_learn==0.5.1->-r requirements.txt (line 8)) (0.35.0)\r\n",
      "Collecting smart-open>=1.8.1\r\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 58 kB 4.4 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython==7.27.0->-r requirements.txt (line 25)) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.27.0->-r requirements.txt (line 25)) (0.2.5)\r\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in /opt/conda/lib/python3.7/site-packages (from pydeck>=0.1.dev5->streamlit==0.83.0->-r requirements.txt (line 3)) (7.6.2)\r\n",
      "Collecting ipykernel>=5.1.2\r\n",
      "  Downloading ipykernel-6.4.1-py3-none-any.whl (124 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 124 kB 68.8 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.83.0->-r requirements.txt (line 3)) (0.2.0)\r\n",
      "Collecting argcomplete>=1.12.3\r\n",
      "  Downloading argcomplete-1.12.3-py2.py3-none-any.whl (38 kB)\r\n",
      "Collecting debugpy<2.0,>=1.0.0\r\n",
      "  Downloading debugpy-1.4.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.9 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 63.6 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: jupyter-client<8.0 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.83.0->-r requirements.txt (line 3)) (6.1.7)\r\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.83.0->-r requirements.txt (line 3)) (3.5.1)\r\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.83.0->-r requirements.txt (line 3)) (1.0.0)\r\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.83.0->-r requirements.txt (line 3)) (5.0.8)\r\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy==3.0.5->-r requirements.txt (line 18)) (1.1.1)\r\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.83.0->-r requirements.txt (line 3)) (4.7.0)\r\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.7/site-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.83.0->-r requirements.txt (line 3)) (20.0.0)\r\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema->ray==1.2.0->-r requirements.txt (line 21)) (0.17.3)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1->-r requirements.txt (line 19)) (1.0.1)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1->-r requirements.txt (line 19)) (3.3.3)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1->-r requirements.txt (line 19)) (1.8.0)\r\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1->-r requirements.txt (line 19)) (1.24.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1->-r requirements.txt (line 19)) (0.4.2)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1->-r requirements.txt (line 19)) (4.6)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1->-r requirements.txt (line 19)) (0.2.7)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1->-r requirements.txt (line 19)) (1.3.0)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1->-r requirements.txt (line 19)) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1->-r requirements.txt (line 19)) (3.0.1)\r\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.7/site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.83.0->-r requirements.txt (line 3)) (5.5.0)\r\n",
      "Requirement already satisfied: Send2Trash in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.83.0->-r requirements.txt (line 3)) (1.5.0)\r\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.83.0->-r requirements.txt (line 3)) (6.0.7)\r\n",
      "Requirement already satisfied: terminado>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.83.0->-r requirements.txt (line 3)) (0.9.2)\r\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->ray==1.2.0->-r requirements.txt (line 21)) (3.0.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->ray==1.2.0->-r requirements.txt (line 21)) (5.1.0)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->ray==1.2.0->-r requirements.txt (line 21)) (1.6.3)\r\n",
      "Requirement already satisfied: hiredis in /opt/conda/lib/python3.7/site-packages (from aioredis->ray==1.2.0->-r requirements.txt (line 21)) (1.1.0)\r\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/lib/python3.7/site-packages (from Flask->mlflow==1.17.0->-r requirements.txt (line 32)) (1.1.0)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from gpustat->ray==1.2.0->-r requirements.txt (line 21)) (5.8.0)\r\n",
      "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /opt/conda/lib/python3.7/site-packages (from gpustat->ray==1.2.0->-r requirements.txt (line 21)) (7.352.0)\r\n",
      "Requirement already satisfied: blessings>=1.6 in /opt/conda/lib/python3.7/site-packages (from gpustat->ray==1.2.0->-r requirements.txt (line 21)) (1.7)\r\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.83.0->-r requirements.txt (line 3)) (0.8.4)\r\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.83.0->-r requirements.txt (line 3)) (3.2.1)\r\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.83.0->-r requirements.txt (line 3)) (0.5.1)\r\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.83.0->-r requirements.txt (line 3)) (1.4.2)\r\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.83.0->-r requirements.txt (line 3)) (0.1.2)\r\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.83.0->-r requirements.txt (line 3)) (0.6.0)\r\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.83.0->-r requirements.txt (line 3)) (0.4.4)\r\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.7/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.83.0->-r requirements.txt (line 3)) (1.4.3)\r\n",
      "Requirement already satisfied: async-generator in /opt/conda/lib/python3.7/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.83.0->-r requirements.txt (line 3)) (1.10)\r\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.83.0->-r requirements.txt (line 3)) (0.5.1)\r\n",
      "Requirement already satisfied: google-api-core<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from opencensus->ray==1.2.0->-r requirements.txt (line 21)) (1.22.4)\r\n",
      "Requirement already satisfied: opencensus-context==0.1.2 in /opt/conda/lib/python3.7/site-packages (from opencensus->ray==1.2.0->-r requirements.txt (line 21)) (0.1.2)\r\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray==1.2.0->-r requirements.txt (line 21)) (1.52.0)\r\n",
      "Requirement already satisfied: pathtools>=0.1.1 in /opt/conda/lib/python3.7/site-packages (from watchdog->streamlit==0.83.0->-r requirements.txt (line 3)) (0.1.2)\r\n",
      "Building wheels for collected packages: python-multipart, sentence-transformers, umap, umap-learn, alembic, databricks-cli, prometheus-flask-exporter\r\n",
      "  Building wheel for python-multipart (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31670 sha256=2f1d2d32ab59d80b762ade5a02291300e9bb1f006587dd028cde5af6e74ebb2f\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/2c/41/7c/bfd1c180534ffdcc0972f78c5758f89881602175d48a8bcd2c\r\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.0.0-py3-none-any.whl size=126709 sha256=adafe8960500cad2c4813718ada55a86637c0933e4847e7c836dc381fe8afca1\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/d1/c1/0f/faafd427f705c4b012274ba60d9a91d75830306811e1355293\r\n",
      "  Building wheel for umap (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for umap: filename=umap-0.1.1-py3-none-any.whl size=3564 sha256=72445fb3fe4e7ad21e9b66ed6443a6746310eff04363e34586c0712bb56e6e96\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/65/55/85/945cfb3d67373767e4dc3e9629300a926edde52633df4f0efe\r\n",
      "  Building wheel for umap-learn (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for umap-learn: filename=umap_learn-0.5.1-py3-none-any.whl size=76566 sha256=418c11d79cdb36dc3a5daaad265d602e76ac609221c77c93b304b9549a995b9c\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/01/e7/bb/347dc0e510803d7116a13d592b10cc68262da56a8eec4dd72f\r\n",
      "  Building wheel for alembic (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158155 sha256=482e3721180c6ea85893d71a72ba2af25c8fc6085c11b644aaf89560b3c00976\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/be/5d/0a/9e13f53f4f5dfb67cd8d245bb7cdffe12f135846f491a283e3\r\n",
      "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for databricks-cli: filename=databricks_cli-0.15.0-py3-none-any.whl size=105260 sha256=ec8b3914486225af8a45fc6acd0ea94ae7884f95a7ba752de07d1d871c65401b\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/e7/ba/75/284f9a90ff7a010bb23b9798f2e9a19dd9fe619379c917bff4\r\n",
      "  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.18.2-py3-none-any.whl size=17399 sha256=23e2baf0742ad72233c9de8cf88af6de0ba18d36fd98c08b3a16d39db42412d3\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/6a/1e/1c/c765920cb92b2f0343d2dd8b481a407cee2823f9b4bbd2e52a\r\n",
      "Successfully built python-multipart sentence-transformers umap umap-learn alembic databricks-cli prometheus-flask-exporter\r\n",
      "Installing collected packages: packaging, matplotlib-inline, ipython, debugpy, argcomplete, ipykernel, numpy, tqdm, scipy, joblib, catalogue, typer, tokenizers, srsly, smart-open, scikit-learn, PyYAML, pydantic, pandas, huggingface-hub, validators, transformers, thinc, starlette, spacy-legacy, querystring-parser, pydeck, prometheus-flask-exporter, pathy, matplotlib, h11, gunicorn, databricks-cli, base58, astor, alembic, xgboost, uvicorn, umap-learn, umap, textblob-fr, tensorflow, streamlit, spacy, sentence-transformers, seaborn, ray, raceplotly, python-multipart, pytest, mlflow, gensim, fastapi\r\n",
      "  Attempting uninstall: packaging\r\n",
      "    Found existing installation: packaging 20.8\r\n",
      "    Uninstalling packaging-20.8:\r\n",
      "      Successfully uninstalled packaging-20.8\r\n",
      "  Attempting uninstall: ipython\r\n",
      "    Found existing installation: ipython 7.19.0\r\n",
      "    Uninstalling ipython-7.19.0:\r\n",
      "      Successfully uninstalled ipython-7.19.0\r\n",
      "  Attempting uninstall: ipykernel\r\n",
      "    Found existing installation: ipykernel 5.1.1\r\n",
      "    Uninstalling ipykernel-5.1.1:\r\n",
      "      Successfully uninstalled ipykernel-5.1.1\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 1.19.5\r\n",
      "    Uninstalling numpy-1.19.5:\r\n",
      "      Successfully uninstalled numpy-1.19.5\r\n",
      "  Attempting uninstall: tqdm\r\n",
      "    Found existing installation: tqdm 4.55.1\r\n",
      "    Uninstalling tqdm-4.55.1:\r\n",
      "      Successfully uninstalled tqdm-4.55.1\r\n",
      "  Attempting uninstall: scipy\r\n",
      "    Found existing installation: scipy 1.4.1\r\n",
      "    Uninstalling scipy-1.4.1:\r\n",
      "      Successfully uninstalled scipy-1.4.1\r\n",
      "  Attempting uninstall: joblib\r\n",
      "    Found existing installation: joblib 1.0.0\r\n",
      "    Uninstalling joblib-1.0.0:\r\n",
      "      Successfully uninstalled joblib-1.0.0\r\n",
      "  Attempting uninstall: catalogue\r\n",
      "    Found existing installation: catalogue 1.0.0\r\n",
      "    Uninstalling catalogue-1.0.0:\r\n",
      "      Successfully uninstalled catalogue-1.0.0\r\n",
      "  Attempting uninstall: tokenizers\r\n",
      "    Found existing installation: tokenizers 0.9.4\r\n",
      "    Uninstalling tokenizers-0.9.4:\r\n",
      "      Successfully uninstalled tokenizers-0.9.4\r\n",
      "  Attempting uninstall: srsly\r\n",
      "    Found existing installation: srsly 1.0.5\r\n",
      "    Uninstalling srsly-1.0.5:\r\n",
      "      Successfully uninstalled srsly-1.0.5\r\n",
      "  Attempting uninstall: smart-open\r\n",
      "    Found existing installation: smart-open 4.1.2\r\n",
      "    Uninstalling smart-open-4.1.2:\r\n",
      "      Successfully uninstalled smart-open-4.1.2\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 0.23.2\r\n",
      "    Uninstalling scikit-learn-0.23.2:\r\n",
      "      Successfully uninstalled scikit-learn-0.23.2\r\n",
      "  Attempting uninstall: PyYAML\r\n",
      "    Found existing installation: PyYAML 5.3.1\r\n",
      "\u001b[31mERROR: Cannot uninstall 'PyYAML'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\u001b[0m\r\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.2.4 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-09-28T14:37:49.118596Z",
     "iopub.status.busy": "2021-09-28T14:37:49.117738Z",
     "iopub.status.idle": "2021-09-28T14:38:02.240576Z",
     "shell.execute_reply": "2021-09-28T14:38:02.239935Z",
     "shell.execute_reply.started": "2021-09-28T13:41:20.459643Z"
    },
    "papermill": {
     "duration": 13.557143,
     "end_time": "2021-09-28T14:38:02.240741",
     "exception": false,
     "start_time": "2021-09-28T14:37:48.683598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\r\n",
      "  Using cached sentence_transformers-2.0.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.8.1)\r\n",
      "Collecting transformers<5.0.0,>=4.6.0\r\n",
      "  Downloading transformers-4.11.0-py3-none-any.whl (2.9 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 168 kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.24.2)\r\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (3.2.4)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.19.2)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.1.95)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.50.2)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.5.2)\r\n",
      "Collecting huggingface-hub\r\n",
      "  Using cached huggingface_hub-0.0.17-py3-none-any.whl (52 kB)\r\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.7.0)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.6.0->sentence-transformers) (0.18.2)\r\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\r\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch>=1.6.0->sentence-transformers) (0.6)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.25.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.12)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (5.3.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.0)\r\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.10.3)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2020.11.13)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.3.0)\r\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.43)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.4.7)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.4.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers) (1.15.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2020.12.5)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.26.2)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (0.17.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence-transformers) (2.1.0)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->sentence-transformers) (7.2.0)\r\n",
      "Installing collected packages: huggingface-hub, transformers, sentence-transformers\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.0.1\r\n",
      "    Uninstalling transformers-4.0.1:\r\n",
      "      Successfully uninstalled transformers-4.0.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "allennlp 1.3.0 requires transformers<4.1,>=4.0, but you have transformers 4.11.0 which is incompatible.\u001b[0m\r\n",
      "Successfully installed huggingface-hub-0.0.17 sentence-transformers-2.0.0 transformers-4.11.0\r\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.2.4 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-09-28T14:38:03.086786Z",
     "iopub.status.busy": "2021-09-28T14:38:03.083085Z",
     "iopub.status.idle": "2021-09-28T14:38:18.681984Z",
     "shell.execute_reply": "2021-09-28T14:38:18.681279Z",
     "shell.execute_reply.started": "2021-09-28T13:41:32.35412Z"
    },
    "papermill": {
     "duration": 16.018114,
     "end_time": "2021-09-28T14:38:18.682128",
     "exception": false,
     "start_time": "2021-09-28T14:38:02.664014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaleido\r\n",
      "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 79.9 MB 153 kB/s \r\n",
      "\u001b[?25hInstalling collected packages: kaleido\r\n",
      "Successfully installed kaleido-0.2.1\r\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.2.4 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# if png doesn't save correctly\n",
    "!pip install kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-09-28T14:38:19.616490Z",
     "iopub.status.busy": "2021-09-28T14:38:19.615891Z",
     "iopub.status.idle": "2021-09-28T14:38:32.904295Z",
     "shell.execute_reply": "2021-09-28T14:38:32.904788Z",
     "shell.execute_reply.started": "2021-09-28T13:41:47.664711Z"
    },
    "papermill": {
     "duration": 13.75369,
     "end_time": "2021-09-28T14:38:32.904967",
     "exception": false,
     "start_time": "2021-09-28T14:38:19.151277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m⚠ Skipping model package dependencies and setting `--no-deps`. You\r\n",
      "don't seem to have the spaCy package itself installed (maybe because you've\r\n",
      "built from source?), so installing the model dependencies would cause spaCy to\r\n",
      "be downloaded, which probably isn't what you want. If the model package has\r\n",
      "other dependencies, you'll have to install them manually.\u001b[0m\r\n",
      "Collecting fr_core_news_md==2.3.0\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_md-2.3.0/fr_core_news_md-2.3.0.tar.gz (46.1 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 46.1 MB 4.1 MB/s \r\n",
      "\u001b[?25hBuilding wheels for collected packages: fr-core-news-md\r\n",
      "  Building wheel for fr-core-news-md (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for fr-core-news-md: filename=fr_core_news_md-2.3.0-py3-none-any.whl size=46100669 sha256=601c4eee68abc7aa7a7d092306b438334ccb957fa2fdad88998d947ca955df0a\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-hb42a5rk/wheels/62/a5/93/9c82d8ae84430ed80720262c11726d046d3444af301b7d2895\r\n",
      "Successfully built fr-core-news-md\r\n",
      "Installing collected packages: fr-core-news-md\r\n",
      "Successfully installed fr-core-news-md-2.3.0\r\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.2.4 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\r\n",
      "You can now load the model via spacy.load('fr_core_news_md')\r\n"
     ]
    }
   ],
   "source": [
    "# if spacy can't load spacy model :\n",
    "!python3 -m spacy download fr_core_news_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.475165,
     "end_time": "2021-09-28T14:38:33.931012",
     "exception": false,
     "start_time": "2021-09-28T14:38:33.455847",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T14:38:34.885806Z",
     "iopub.status.busy": "2021-09-28T14:38:34.884642Z",
     "iopub.status.idle": "2021-09-28T14:39:01.137238Z",
     "shell.execute_reply": "2021-09-28T14:39:01.135942Z",
     "shell.execute_reply.started": "2021-09-28T13:42:02.449272Z"
    },
    "papermill": {
     "duration": 26.731227,
     "end_time": "2021-09-28T14:39:01.137428",
     "exception": false,
     "start_time": "2021-09-28T14:38:34.406201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from autonlp.autonlp import AutoNLP\n",
    "import os\n",
    "from pathlib import Path\n",
    "from autonlp.flags import Flags, save_yaml\n",
    "import dataclasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.486897,
     "end_time": "2021-09-28T14:39:02.163852",
     "exception": false,
     "start_time": "2021-09-28T14:39:01.676955",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Flags update (parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T14:39:03.126903Z",
     "iopub.status.busy": "2021-09-28T14:39:03.125679Z",
     "iopub.status.idle": "2021-09-28T14:39:04.639081Z",
     "shell.execute_reply": "2021-09-28T14:39:04.638430Z",
     "shell.execute_reply.started": "2021-09-28T13:59:20.320219Z"
    },
    "papermill": {
     "duration": 1.992123,
     "end_time": "2021-09-28T14:39:04.639225",
     "exception": false,
     "start_time": "2021-09-28T14:39:02.647102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add logs from optimization to outdir :\n",
    "!cp -r /kaggle/input/logs-validation/logs /kaggle/working/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T14:39:05.681305Z",
     "iopub.status.busy": "2021-09-28T14:39:05.667011Z",
     "iopub.status.idle": "2021-09-28T14:39:05.686045Z",
     "shell.execute_reply": "2021-09-28T14:39:05.685453Z",
     "shell.execute_reply.started": "2021-09-28T13:42:29.996584Z"
    },
    "papermill": {
     "duration": 0.537905,
     "end_time": "2021-09-28T14:39:05.686187",
     "exception": false,
     "start_time": "2021-09-28T14:39:05.148282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flags : Flags(path_data='/kaggle/input/finance-corpus/FinancialPhraseBank_train.csv', path_data_validation='', apply_logs=True, outdir='/kaggle/working/logs', apply_mlflow=False, experiment_name='Experiment', apply_app=False, debug=False, seed=15, column_text='text_fr', language_text='fr', target='sentiment', apply_small_clean=True, name_spacy_model='fr_core_news_md', apply_spacy_preprocessing=True, apply_entity_preprocessing=True, objective='multi-class', embedding={'tf': 1, 'tf-idf': 2, 'word2vec': None, 'fasttext': None, 'doc2vec': None, 'transformer': None}, classifier={'Naive_Bayes': [1], 'Logistic_Regression': [1], 'SGD_Classifier': [2], 'XGBoost': [], 'Global_Average': [], 'Attention': [], 'BiRNN': [], 'BiRNN_Attention': [], 'biLSTM': [], 'BiLSTM_Attention': [], 'biGRU': [], 'BiGRU_Attention': []}, regressor={'SGD_Regressor': [1], 'XGBoost': [], 'Global_Average': [2], 'Attention': [], 'BiRNN': [], 'BiRNN_Attention': [], 'biLSTM': [], 'BiLSTM_Attention': [], 'biGRU': [], 'BiGRU_Attention': []}, clustering={'NMF_frobenius': [1], 'NMF_kullback': [], 'LDA': [], 'hdbscan': [], 'ACP_hdbscan': [], 'UMAP_hdbscan': [], 'kmeans': [], 'ACP_kmeans': [2], 'UMAP_kmeans': [], 'agglomerativeclustering': [], 'ACP_agglomerativeclustering': [], 'UMAP_agglomerativeclustering': [], 'Zero_shot': []}, max_run_time_per_model=60, max_trial_per_model=1000, frac_trainset=0.7, nfolds=5, nfolds_train=5, scoring='f1', average_scoring='macro', cv_strategy='KFold', class_weight=True, size_params='small', method_embedding={'Word2vec': 'Word2Vec', 'Fasttext': 'FastText', 'Doc2Vec': 'Doc2Vec', 'Transformer': 'CamemBERT', 'spacy': [(['ADJ', 'NOUN', 'VERB'], True)]}, apply_optimization=False, apply_validation=True, apply_blend_model=True, path_models_parameters=None, path_models_best_parameters=None, verbose=2, batch_size=32, patience=2, epochs=60, min_lr=0.0001, apply_ray=False, ray_max_model_parallel=1, ray_cpu_per_model=1, ray_gpu_per_model=0, ray_verbose=2, sort_leaderboard='f1', map_label={}, dimension_embedding='doc_embedding', n_groups=7, alpha_nmf=0.1, l1_ratio=0.5, max_iter_lda=5, acp_n_components=2, umap_n_components=2, umap_n_neighbors=15, min_cluster_size=15, aglc_linkage='ward', vocabulary_labels={'positif': ['positif', 'bien'], 'négatif': ['négatif', 'mauvais']}, show_top_terms_topics=False, preprocess_topic=(['ADJ', 'NOUN', 'VERB'], True), n_top_words=10, min_ngram=1, max_ngram=1, tf_binary=False, tf_ngram_range=[(1, 1), (1, 2), (1, 3)], tf_stop_words=True, tf_wde_binary=False, tf_wde_stop_words=True, tf_wde_ngram_range=(1, 1), tf_wde_vector_size=200, tf_wde_max_features=20000, tf_wde_maxlen=250, tf_wde_learning_rate=[0.001], tfidf_binary=False, tfidf_ngram_range=[(1, 1), (1, 2), (1, 3)], tfidf_stop_words=True, tfidf_wde_binary=False, tfidf_wde_stop_words=True, tfidf_wde_ngram_range=(1, 1), tfidf_wde_vector_size=200, tfidf_wde_max_features=20000, tfidf_wde_maxlen=250, tfidf_wde_learning_rate=[0.001], w2v_size_vector=300, w2v_window=5, w2v_epochs=10, w2v_sg=0, w2v_maxlen=250, w2v_max_features=20000, w2v_learning_rate=[0.001], ft_size_vector=300, ft_window=5, ft_epochs=10, ft_thr_grams=10, ft_sg=0, ft_maxlen=250, ft_max_features=20000, ft_learning_rate=[0.001], d2v_size_vector=300, d2v_window=5, d2v_epochs=10, d2v_sg=0, d2v_maxlen=250, d2v_max_features=20000, d2v_learning_rate=[0.001], tr_maxlen=100, tr_learning_rate=[3e-05], nb_alpha_min=0.0, nb_alpha_max=1.0, logr_C_min=0.01, logr_C_max=100.0, logr_penalty=['l2', 'l1'], sgd_alpha_min=0.0001, sgd_alpha_max=0.01, sgdc_penalty=['l2', 'l1'], sgdc_loss=['log', 'modified_huber'], sgdr_penalty=['l2', 'l1'], sgdr_loss=['squared_loss', 'huber', 'epsilon_insensitive'], xgb_n_estimators_min=20, xgb_n_estimators_max=200, xgb_max_depth_min=3, xgb_max_depth_max=10, xgb_learning_rate_min=0.04, xgb_learning_rate_max=0.3, xgb_subsample_min=0.5, xgb_subsample_max=1.0, ga_dropout_rate_min=0, ga_dropout_rate_max=0.5, rnn_hidden_unit_min=120, rnn_hidden_unit_max=130, rnn_dropout_rate_min=0, rnn_dropout_rate_max=0.5, lstm_hidden_unit_min=120, lstm_hidden_unit_max=130, lstm_dropout_rate_min=0, lstm_dropout_rate_max=0.5, gru_hidden_unit_min=120, gru_hidden_unit_max=130, gru_dropout_rate_min=0, gru_dropout_rate_max=0.5, att_dropout_rate_min=0, att_dropout_rate_max=0.5)\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "# Parameters\n",
    "#####################\n",
    "\n",
    "flags_dict_info = {\n",
    "    \"path_data\": \"/kaggle/input/finance-corpus/FinancialPhraseBank_train.csv\",\n",
    "    \"path_data_validation\": \"\",\n",
    "    \"apply_logs\": True,\n",
    "    \"outdir\": \"/kaggle/working/logs\",\n",
    "    \"seed\": 15,\n",
    "    \"debug\": False,  # for debug : use only 50 data rows for training\n",
    "}\n",
    "flags_dict_preprocessing = {\n",
    "    \"column_text\": \"text_fr\",  # name column with texts\n",
    "    \"target\": \"sentiment\",     # name column with targets\n",
    "    \"language_text\": \"fr\",\n",
    "    \"apply_small_clean\": True,\n",
    "    \"name_spacy_model\": \"fr_core_news_md\",\n",
    "    \"apply_spacy_preprocessing\": True,\n",
    "    \"apply_entity_preprocessing\": True\n",
    "}\n",
    "\n",
    "flags_dict_autonlp = {\n",
    "    \"objective\": 'multi-class',    # 'binary' or 'multi-class' or 'regression'\n",
    "    \n",
    "    \"embedding\": {\"tf\": 1, \"tf-idf\": 2, \"word2vec\": None, \"fasttext\": None, \"doc2vec\": None, \"transformer\": None},\n",
    "    \n",
    "    \"classifier\": {\"Naive_Bayes\": [1], \"Logistic_Regression\": [1], \"SGD_Classifier\": [2],\n",
    "                   \"XGBoost\": [], \"Global_Average\": [], \"Attention\": [], \"BiRNN\": [], \"BiRNN_Attention\": [],\n",
    "                   \"biLSTM\": [], \"BiLSTM_Attention\": [], \"biGRU\": [], \"BiGRU_Attention\": []},\n",
    "    \n",
    "    \"max_run_time_per_model\": 60,\n",
    "    \"frac_trainset\": 0.7,\n",
    "    \"scoring\": 'f1',\n",
    "    \"average_scoring\": \"macro\",\n",
    "    \"nfolds\": 5,\n",
    "    \"nfolds_train\": 5,\n",
    "    \"class_weight\": True,\n",
    "    \"apply_blend_model\": True,\n",
    "    \"verbose\": 2,\n",
    "    \"method_embedding\": {'Word2vec': 'Word2Vec',\n",
    "                         'Fasttext': 'FastText',\n",
    "                         'Doc2Vec': 'Doc2Vec',\n",
    "                         'Transformer': 'CamemBERT',\n",
    "                         'spacy': [(['ADJ', 'NOUN', 'VERB'], True)]},\n",
    "\n",
    "    \"apply_optimization\": False,\n",
    "    \"apply_validation\": True,\n",
    "    \n",
    "    \"batch_size\":32,\n",
    "    \"tr_learning_rate\": [3e-5],\n",
    "    \"tr_maxlen\": 100,\n",
    "    \"patience\":2\n",
    "}\n",
    "\n",
    "flags_dict_display = {\n",
    "    \"sort_leaderboard\": 'f1'\n",
    "}\n",
    "\n",
    "flags = Flags().update(flags_dict_info)\n",
    "flags = flags.update(flags_dict_preprocessing)\n",
    "flags = flags.update(flags_dict_autonlp)\n",
    "flags = flags.update(flags_dict_display)\n",
    "print(\"flags :\", flags)\n",
    "debug = flags.debug\n",
    "outdir = Path(flags.outdir)\n",
    "os.makedirs(str(outdir), exist_ok=True)\n",
    "flags_dict = dataclasses.asdict(flags)\n",
    "save_yaml(outdir / \"flags.yaml\", flags_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.466347,
     "end_time": "2021-09-28T14:39:06.687343",
     "exception": false,
     "start_time": "2021-09-28T14:39:06.220996",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T14:39:07.662735Z",
     "iopub.status.busy": "2021-09-28T14:39:07.662097Z",
     "iopub.status.idle": "2021-09-28T14:39:07.665801Z",
     "shell.execute_reply": "2021-09-28T14:39:07.665298Z",
     "shell.execute_reply.started": "2021-09-28T13:42:30.029213Z"
    },
    "papermill": {
     "duration": 0.508344,
     "end_time": "2021-09-28T14:39:07.665949",
     "exception": false,
     "start_time": "2021-09-28T14:39:07.157605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "autonlp = AutoNLP(flags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.480693,
     "end_time": "2021-09-28T14:39:08.624953",
     "exception": false,
     "start_time": "2021-09-28T14:39:08.144260",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T14:39:09.654267Z",
     "iopub.status.busy": "2021-09-28T14:39:09.653115Z",
     "iopub.status.idle": "2021-09-28T14:39:36.599404Z",
     "shell.execute_reply": "2021-09-28T14:39:36.598356Z",
     "shell.execute_reply.started": "2021-09-28T13:42:30.055579Z"
    },
    "papermill": {
     "duration": 27.493174,
     "end_time": "2021-09-28T14:39:36.599567",
     "exception": false,
     "start_time": "2021-09-28T14:39:09.106393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Read data...\n",
      "\n",
      "Begin preparation of 3876 data :\n",
      "\n",
      "Training set size : 2713\n",
      "Test set size : 1163\n",
      "\n",
      "Begin preprocessing of 2713 train data :\n",
      "\u001b[38;5;3m⚠ Skipping model package dependencies and setting `--no-deps`. You\n",
      "don't seem to have the spaCy package itself installed (maybe because you've\n",
      "built from source?), so installing the model dependencies would cause spaCy to\n",
      "be downloaded, which probably isn't what you want. If the model package has\n",
      "other dependencies, you'll have to install them manually.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('fr_core_news_md')\n",
      "- Apply small clean of texts...\n",
      "- Apply nlp.pipe from spacy...\n",
      "- Apply entities preprocessing...\n",
      "\n",
      "Begin preprocessing of 1163 test data :\n",
      "- Apply small clean of texts...\n",
      "- Apply nlp.pipe from spacy...\n",
      "- Apply entities preprocessing...\n",
      "CPU times: user 19.9 s, sys: 1.67 s, total: 21.5 s\n",
      "Wall time: 26.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "autonlp.data_preprocessing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.47217,
     "end_time": "2021-09-28T14:39:37.539142",
     "exception": false,
     "start_time": "2021-09-28T14:39:37.066972",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T14:39:38.492956Z",
     "iopub.status.busy": "2021-09-28T14:39:38.491858Z",
     "iopub.status.idle": "2021-09-28T14:39:38.493862Z",
     "shell.execute_reply": "2021-09-28T14:39:38.494407Z",
     "shell.execute_reply.started": "2021-09-28T13:42:58.020832Z"
    },
    "papermill": {
     "duration": 0.482453,
     "end_time": "2021-09-28T14:39:38.494580",
     "exception": false,
     "start_time": "2021-09-28T14:39:38.012127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#autonlp.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.50542,
     "end_time": "2021-09-28T14:39:39.465969",
     "exception": false,
     "start_time": "2021-09-28T14:39:38.960549",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Leaderboard (Train score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T14:39:40.428273Z",
     "iopub.status.busy": "2021-09-28T14:39:40.427623Z",
     "iopub.status.idle": "2021-09-28T14:39:40.431141Z",
     "shell.execute_reply": "2021-09-28T14:39:40.430509Z",
     "shell.execute_reply.started": "2021-09-28T13:42:58.029543Z"
    },
    "papermill": {
     "duration": 0.486347,
     "end_time": "2021-09-28T14:39:40.431292",
     "exception": false,
     "start_time": "2021-09-28T14:39:39.944945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#leaderboard_train = autonlp.get_leaderboard(sort_by=flags.sort_leaderboard, dataset='train')\n",
    "#print('Train Leaderboard')\n",
    "#leaderboard_train.to_csv(os.path.join(flags.outdir,'leaderboard_train.csv'), index=False)\n",
    "#leaderboard_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.468669,
     "end_time": "2021-09-28T14:39:41.376778",
     "exception": false,
     "start_time": "2021-09-28T14:39:40.908109",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Leaderboard (Validation score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T14:39:42.318379Z",
     "iopub.status.busy": "2021-09-28T14:39:42.317417Z",
     "iopub.status.idle": "2021-09-28T14:39:42.320715Z",
     "shell.execute_reply": "2021-09-28T14:39:42.320132Z",
     "shell.execute_reply.started": "2021-09-28T13:42:58.040234Z"
    },
    "papermill": {
     "duration": 0.475731,
     "end_time": "2021-09-28T14:39:42.320864",
     "exception": false,
     "start_time": "2021-09-28T14:39:41.845133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#leaderboard_val = autonlp.get_leaderboard(sort_by=flags.sort_leaderboard, dataset='val')\n",
    "#print('\\nValidation Leaderboard')\n",
    "#leaderboard_val.to_csv(os.path.join(flags.outdir,'leaderboard_val.csv'), index=False)\n",
    "#leaderboard_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T14:39:43.266918Z",
     "iopub.status.busy": "2021-09-28T14:39:43.266156Z",
     "iopub.status.idle": "2021-09-28T14:39:43.269657Z",
     "shell.execute_reply": "2021-09-28T14:39:43.269149Z",
     "shell.execute_reply.started": "2021-09-28T13:42:58.051908Z"
    },
    "papermill": {
     "duration": 0.480743,
     "end_time": "2021-09-28T14:39:43.269816",
     "exception": false,
     "start_time": "2021-09-28T14:39:42.789073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# correlation between oof_val predictions\n",
    "#autonlp.correlation_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T14:39:44.232914Z",
     "iopub.status.busy": "2021-09-28T14:39:44.231903Z",
     "iopub.status.idle": "2021-09-28T14:39:44.235343Z",
     "shell.execute_reply": "2021-09-28T14:39:44.236005Z",
     "shell.execute_reply.started": "2021-09-28T13:42:58.062886Z"
    },
    "papermill": {
     "duration": 0.488062,
     "end_time": "2021-09-28T14:39:44.236204",
     "exception": false,
     "start_time": "2021-09-28T14:39:43.748142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df_all_results = pd.read_csv(\"/kaggle/working/logs/df_all_results.csv\")\n",
    "#if len(df_all_results) > 0:\n",
    "#    df_all_results_mean = df_all_results.groupby('model').mean().sort_values('mean_test_score', ascending=False)\n",
    "#    print('\\nGridSearch information Leaderboard')\n",
    "#    df_all_results.to_csv(os.path.join(flags.outdir,'df_all_results_mean.csv'), index=False)\n",
    "#    print(df_all_results_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T14:39:45.219510Z",
     "iopub.status.busy": "2021-09-28T14:39:45.218921Z",
     "iopub.status.idle": "2021-09-28T14:39:45.223408Z",
     "shell.execute_reply": "2021-09-28T14:39:45.223936Z",
     "shell.execute_reply.started": "2021-09-28T13:42:58.074487Z"
    },
    "papermill": {
     "duration": 0.506884,
     "end_time": "2021-09-28T14:39:45.224115",
     "exception": false,
     "start_time": "2021-09-28T14:39:44.717231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df_all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T14:39:46.181733Z",
     "iopub.status.busy": "2021-09-28T14:39:46.181094Z",
     "iopub.status.idle": "2021-09-28T14:39:46.185742Z",
     "shell.execute_reply": "2021-09-28T14:39:46.186258Z",
     "shell.execute_reply.started": "2021-09-28T13:42:58.089499Z"
    },
    "papermill": {
     "duration": 0.485455,
     "end_time": "2021-09-28T14:39:46.186437",
     "exception": false,
     "start_time": "2021-09-28T14:39:45.700982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df_all_results.groupby(['model'])['mean_test_score'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T14:39:47.121456Z",
     "iopub.status.busy": "2021-09-28T14:39:47.120836Z",
     "iopub.status.idle": "2021-09-28T14:39:47.125599Z",
     "shell.execute_reply": "2021-09-28T14:39:47.126214Z",
     "shell.execute_reply.started": "2021-09-28T13:42:58.100999Z"
    },
    "papermill": {
     "duration": 0.472359,
     "end_time": "2021-09-28T14:39:47.126405",
     "exception": false,
     "start_time": "2021-09-28T14:39:46.654046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from PIL import Image\n",
    "#Image.open(os.path.join(flags.outdir, 'boxplot_df_all_results.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T14:39:48.087991Z",
     "iopub.status.busy": "2021-09-28T14:39:48.087303Z",
     "iopub.status.idle": "2021-09-28T14:39:48.091773Z",
     "shell.execute_reply": "2021-09-28T14:39:48.092314Z",
     "shell.execute_reply.started": "2021-09-28T13:42:58.113869Z"
    },
    "papermill": {
     "duration": 0.490443,
     "end_time": "2021-09-28T14:39:48.092490",
     "exception": false,
     "start_time": "2021-09-28T14:39:47.602047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#try:\n",
    "#    Image.open(os.path.join(flags.outdir, 'last_logs', 'metric_scores_val.png'))\n",
    "#except:\n",
    "#    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.488915,
     "end_time": "2021-09-28T14:39:49.064958",
     "exception": false,
     "start_time": "2021-09-28T14:39:48.576043",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Testing on test set from train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T14:39:50.042901Z",
     "iopub.status.busy": "2021-09-28T14:39:50.042246Z",
     "iopub.status.idle": "2021-09-28T14:39:55.135775Z",
     "shell.execute_reply": "2021-09-28T14:39:55.136186Z",
     "shell.execute_reply.started": "2021-09-28T13:59:28.719161Z"
    },
    "papermill": {
     "duration": 5.583892,
     "end_time": "2021-09-28T14:39:55.136364",
     "exception": false,
     "start_time": "2021-09-28T14:39:49.552472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[4mtf+Logistic_Regression_ADJ_NOUN_VERB_lem Model\u001b[0m:\n",
      "Model fold2.joblib:\n",
      "Inference : 1163 samples in 0.03335428237915039 sec ( 34868.08640580995 / sample).\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.7446\n",
      "precision macro = 0.7017\n",
      "recall macro = 0.6526\n",
      "f1 score macro = 0.672\n",
      "\n",
      "\n",
      "Model fold3.joblib:\n",
      "Inference : 1163 samples in 0.03677535057067871 sec ( 31624.44360019968 / sample).\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.7291\n",
      "precision macro = 0.6835\n",
      "recall macro = 0.6285\n",
      "f1 score macro = 0.6501\n",
      "\n",
      "\n",
      "Model fold0.joblib:\n",
      "Inference : 1163 samples in 0.03709578514099121 sec ( 31351.27065190146 / sample).\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.7549\n",
      "precision macro = 0.7116\n",
      "recall macro = 0.6514\n",
      "f1 score macro = 0.6748\n",
      "\n",
      "\n",
      "Model fold4.joblib:\n",
      "Inference : 1163 samples in 0.03315329551696777 sec ( 35079.468929560244 / sample).\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.7592\n",
      "precision macro = 0.7183\n",
      "recall macro = 0.677\n",
      "f1 score macro = 0.6946\n",
      "\n",
      "\n",
      "Model fold1.joblib:\n",
      "Inference : 1163 samples in 0.032527923583984375 sec ( 35753.89609475783 / sample).\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.7524\n",
      "precision macro = 0.7084\n",
      "recall macro = 0.6637\n",
      "f1 score macro = 0.6819\n",
      "\n",
      "\n",
      "Model Ensemble Average:\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.7575\n",
      "precision macro = 0.7237\n",
      "recall macro = 0.6598\n",
      "f1 score macro = 0.6848\n",
      "\n",
      "\n",
      "\n",
      "\u001b[4mtf+Naive_Bayes_ADJ_NOUN_VERB_lem Model\u001b[0m:\n",
      "Model fold2.joblib:\n",
      "Inference : 1163 samples in 0.025137662887573242 sec ( 46265.23974012425 / sample).\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.7077\n",
      "precision macro = 0.651\n",
      "recall macro = 0.6421\n",
      "f1 score macro = 0.6459\n",
      "\n",
      "\n",
      "Model fold3.joblib:\n",
      "Inference : 1163 samples in 0.027202606201171875 sec ( 42753.256485766375 / sample).\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.712\n",
      "precision macro = 0.6723\n",
      "recall macro = 0.6353\n",
      "f1 score macro = 0.6511\n",
      "\n",
      "\n",
      "Model fold0.joblib:\n",
      "Inference : 1163 samples in 0.026044130325317383 sec ( 44654.97543872498 / sample).\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.7102\n",
      "precision macro = 0.6611\n",
      "recall macro = 0.6354\n",
      "f1 score macro = 0.6469\n",
      "\n",
      "\n",
      "Model fold4.joblib:\n",
      "Inference : 1163 samples in 0.02847599983215332 sec ( 40841.41055116923 / sample).\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.7085\n",
      "precision macro = 0.6533\n",
      "recall macro = 0.6448\n",
      "f1 score macro = 0.6484\n",
      "\n",
      "\n",
      "Model fold1.joblib:\n",
      "Inference : 1163 samples in 0.026155471801757812 sec ( 44464.883249471306 / sample).\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.7102\n",
      "precision macro = 0.6544\n",
      "recall macro = 0.6499\n",
      "f1 score macro = 0.6507\n",
      "\n",
      "\n",
      "Model Ensemble Average:\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.7102\n",
      "precision macro = 0.6579\n",
      "recall macro = 0.6393\n",
      "f1 score macro = 0.6474\n",
      "\n",
      "\n",
      "\n",
      "\u001b[4mtf-idf+SGD_Classifier_ADJ_NOUN_VERB_lem Model\u001b[0m:\n",
      "Model fold2.joblib:\n",
      "Inference : 1163 samples in 0.01662731170654297 sec ( 69945.1613421279 / sample).\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.736\n",
      "precision macro = 0.6855\n",
      "recall macro = 0.6543\n",
      "f1 score macro = 0.6676\n",
      "\n",
      "\n",
      "Model fold3.joblib:\n",
      "Inference : 1163 samples in 0.015342235565185547 sec ( 75803.81588189588 / sample).\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.7463\n",
      "precision macro = 0.711\n",
      "recall macro = 0.6786\n",
      "f1 score macro = 0.693\n",
      "\n",
      "\n",
      "Model fold0.joblib:\n",
      "Inference : 1163 samples in 0.0188138484954834 sec ( 61816.16697291886 / sample).\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.7438\n",
      "precision macro = 0.7029\n",
      "recall macro = 0.6657\n",
      "f1 score macro = 0.6817\n",
      "\n",
      "\n",
      "Model fold4.joblib:\n",
      "Inference : 1163 samples in 0.01706981658935547 sec ( 68131.95642214648 / sample).\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.7446\n",
      "precision macro = 0.6915\n",
      "recall macro = 0.6718\n",
      "f1 score macro = 0.6808\n",
      "\n",
      "\n",
      "Model fold1.joblib:\n",
      "Inference : 1163 samples in 0.015331268310546875 sec ( 75858.04229907937 / sample).\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.7334\n",
      "precision macro = 0.6795\n",
      "recall macro = 0.6541\n",
      "f1 score macro = 0.6645\n",
      "\n",
      "\n",
      "Model Ensemble Average:\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.7567\n",
      "precision macro = 0.7217\n",
      "recall macro = 0.6722\n",
      "f1 score macro = 0.6928\n",
      "\n",
      "\n",
      "\n",
      "\u001b[4mBlendModel Model\u001b[0m:\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.761\n",
      "precision macro = 0.7255\n",
      "recall macro = 0.6768\n",
      "f1 score macro = 0.6968\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "name_logs = 'best_logs'\n",
    "on_test_data = True\n",
    "autonlp.leader_predict(name_logs = name_logs, on_test_data = on_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T14:39:56.215118Z",
     "iopub.status.busy": "2021-09-28T14:39:56.214151Z",
     "iopub.status.idle": "2021-09-28T14:39:56.237605Z",
     "shell.execute_reply": "2021-09-28T14:39:56.238099Z",
     "shell.execute_reply.started": "2021-09-28T13:42:58.139566Z"
    },
    "papermill": {
     "duration": 0.566115,
     "end_time": "2021-09-28T14:39:56.238318",
     "exception": false,
     "start_time": "2021-09-28T14:39:55.672203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Leaderboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>recall_macro_test</th>\n",
       "      <th>precision_macro_test</th>\n",
       "      <th>f1_macro_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BlendModel</td>\n",
       "      <td>0.7610</td>\n",
       "      <td>0.6768</td>\n",
       "      <td>0.7255</td>\n",
       "      <td>0.6968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tf-idf+SGD_Classifier_ADJ_NOUN_VERB_lem</td>\n",
       "      <td>0.7567</td>\n",
       "      <td>0.6722</td>\n",
       "      <td>0.7217</td>\n",
       "      <td>0.6928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tf+Logistic_Regression_ADJ_NOUN_VERB_lem</td>\n",
       "      <td>0.7575</td>\n",
       "      <td>0.6598</td>\n",
       "      <td>0.7237</td>\n",
       "      <td>0.6848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tf+Naive_Bayes_ADJ_NOUN_VERB_lem</td>\n",
       "      <td>0.7102</td>\n",
       "      <td>0.6393</td>\n",
       "      <td>0.6579</td>\n",
       "      <td>0.6474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       name  accuracy_test  recall_macro_test  \\\n",
       "3                                BlendModel         0.7610             0.6768   \n",
       "2   tf-idf+SGD_Classifier_ADJ_NOUN_VERB_lem         0.7567             0.6722   \n",
       "0  tf+Logistic_Regression_ADJ_NOUN_VERB_lem         0.7575             0.6598   \n",
       "1          tf+Naive_Bayes_ADJ_NOUN_VERB_lem         0.7102             0.6393   \n",
       "\n",
       "   precision_macro_test  f1_macro_test  \n",
       "3                0.7255         0.6968  \n",
       "2                0.7217         0.6928  \n",
       "0                0.7237         0.6848  \n",
       "1                0.6579         0.6474  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard_test = autonlp.get_leaderboard(sort_by=flags.sort_leaderboard, dataset='test', info_models=autonlp.info_models)\n",
    "print('\\nTest Leaderboard')\n",
    "leaderboard_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.565455,
     "end_time": "2021-09-28T14:39:57.378286",
     "exception": false,
     "start_time": "2021-09-28T14:39:56.812831",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Testing on other test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T14:39:58.501433Z",
     "iopub.status.busy": "2021-09-28T14:39:58.500514Z",
     "iopub.status.idle": "2021-09-28T14:39:58.530948Z",
     "shell.execute_reply": "2021-09-28T14:39:58.530421Z",
     "shell.execute_reply.started": "2021-09-28T13:42:58.16231Z"
    },
    "papermill": {
     "duration": 0.561609,
     "end_time": "2021-09-28T14:39:58.531121",
     "exception": false,
     "start_time": "2021-09-28T14:39:57.969512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(\"/kaggle/input/finance-corpus/FinancialPhraseBank_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T14:39:59.584033Z",
     "iopub.status.busy": "2021-09-28T14:39:59.583339Z",
     "iopub.status.idle": "2021-09-28T14:40:02.936390Z",
     "shell.execute_reply": "2021-09-28T14:40:02.935679Z",
     "shell.execute_reply.started": "2021-09-28T13:42:58.191452Z"
    },
    "papermill": {
     "duration": 3.88111,
     "end_time": "2021-09-28T14:40:02.936549",
     "exception": false,
     "start_time": "2021-09-28T14:39:59.055439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Apply small clean of texts...\n",
      "- Apply nlp.pipe from spacy...\n",
      "- Apply entities preprocessing...\n"
     ]
    }
   ],
   "source": [
    "X_test, doc_spacy_data_test, Y_test = autonlp.preprocess_test_data(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T14:40:03.950313Z",
     "iopub.status.busy": "2021-09-28T14:40:03.949323Z",
     "iopub.status.idle": "2021-09-28T14:40:05.961431Z",
     "shell.execute_reply": "2021-09-28T14:40:05.960165Z",
     "shell.execute_reply.started": "2021-09-28T13:43:01.093886Z"
    },
    "papermill": {
     "duration": 2.523551,
     "end_time": "2021-09-28T14:40:05.961589",
     "exception": false,
     "start_time": "2021-09-28T14:40:03.438038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[4mtf+Logistic_Regression_ADJ_NOUN_VERB_lem Model\u001b[0m:\n",
      "Model fold2.joblib:\n",
      "Inference : 969 samples in 0.029127836227416992 sec ( 33267.146671468676 / sample).\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.7389\n",
      "precision macro = 0.6945\n",
      "recall macro = 0.6453\n",
      "f1 score macro = 0.665\n",
      "\n",
      "\n",
      "Model fold3.joblib:\n",
      "Inference : 969 samples in 0.028990507125854492 sec ( 33424.73437230149 / sample).\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.7307\n",
      "precision macro = 0.6916\n",
      "recall macro = 0.6398\n",
      "f1 score macro = 0.6604\n",
      "\n",
      "\n",
      "Model fold0.joblib:\n",
      "Inference : 969 samples in 0.02864384651184082 sec ( 33829.25542487577 / sample).\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.7492\n",
      "precision macro = 0.7082\n",
      "recall macro = 0.6546\n",
      "f1 score macro = 0.6759\n",
      "\n",
      "\n",
      "Model fold4.joblib:\n",
      "Inference : 969 samples in 0.02941107749938965 sec ( 32946.76980196013 / sample).\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.7399\n",
      "precision macro = 0.7016\n",
      "recall macro = 0.6459\n",
      "f1 score macro = 0.6678\n",
      "\n",
      "\n",
      "Model fold1.joblib:\n",
      "Inference : 969 samples in 0.02834153175354004 sec ( 34190.10688718212 / sample).\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.742\n",
      "precision macro = 0.6954\n",
      "recall macro = 0.6577\n",
      "f1 score macro = 0.6733\n",
      "\n",
      "\n",
      "Model Ensemble Average:\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.742\n",
      "precision macro = 0.7025\n",
      "recall macro = 0.6468\n",
      "f1 score macro = 0.6686\n",
      "\n",
      "\n",
      "\n",
      "\u001b[4mtf+Naive_Bayes_ADJ_NOUN_VERB_lem Model\u001b[0m:\n",
      "Model fold2.joblib:\n",
      "Inference : 969 samples in 0.021310806274414062 sec ( 45469.88919717175 / sample).\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.6904\n",
      "precision macro = 0.6244\n",
      "recall macro = 0.6257\n",
      "f1 score macro = 0.6232\n",
      "\n",
      "\n",
      "Model fold3.joblib:\n",
      "Inference : 969 samples in 0.02194809913635254 sec ( 44149.60922037433 / sample).\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.7038\n",
      "precision macro = 0.6505\n",
      "recall macro = 0.6424\n",
      "f1 score macro = 0.6462\n",
      "\n",
      "\n",
      "Model fold0.joblib:\n",
      "Inference : 969 samples in 0.022841691970825195 sec ( 42422.42655393769 / sample).\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.709\n",
      "precision macro = 0.6481\n",
      "recall macro = 0.6417\n",
      "f1 score macro = 0.6445\n",
      "\n",
      "\n",
      "Model fold4.joblib:\n",
      "Inference : 969 samples in 0.020758628845214844 sec ( 46679.383654155376 / sample).\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.7069\n",
      "precision macro = 0.6459\n",
      "recall macro = 0.6496\n",
      "f1 score macro = 0.6471\n",
      "\n",
      "\n",
      "Model fold1.joblib:\n",
      "Inference : 969 samples in 0.02100396156311035 sec ( 46134.154125566136 / sample).\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.6976\n",
      "precision macro = 0.6358\n",
      "recall macro = 0.6418\n",
      "f1 score macro = 0.6378\n",
      "\n",
      "\n",
      "Model Ensemble Average:\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.7069\n",
      "precision macro = 0.6474\n",
      "recall macro = 0.6477\n",
      "f1 score macro = 0.6468\n",
      "\n",
      "\n",
      "\n",
      "\u001b[4mtf-idf+SGD_Classifier_ADJ_NOUN_VERB_lem Model\u001b[0m:\n",
      "Model fold2.joblib:\n",
      "Inference : 969 samples in 0.013674497604370117 sec ( 70861.83551564816 / sample).\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.7337\n",
      "precision macro = 0.6949\n",
      "recall macro = 0.6495\n",
      "f1 score macro = 0.6681\n",
      "\n",
      "\n",
      "Model fold3.joblib:\n",
      "Inference : 969 samples in 0.014607667922973633 sec ( 66335.0238456642 / sample).\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.7265\n",
      "precision macro = 0.6822\n",
      "recall macro = 0.6644\n",
      "f1 score macro = 0.6724\n",
      "\n",
      "\n",
      "Model fold0.joblib:\n",
      "Inference : 969 samples in 0.017009973526000977 sec ( 56966.57896138482 / sample).\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.741\n",
      "precision macro = 0.7009\n",
      "recall macro = 0.6587\n",
      "f1 score macro = 0.6763\n",
      "\n",
      "\n",
      "Model fold4.joblib:\n",
      "Inference : 969 samples in 0.016952037811279297 sec ( 57161.26938764029 / sample).\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.7286\n",
      "precision macro = 0.6851\n",
      "recall macro = 0.6656\n",
      "f1 score macro = 0.6738\n",
      "\n",
      "\n",
      "Model fold1.joblib:\n",
      "Inference : 969 samples in 0.01522374153137207 sec ( 63650.58142922024 / sample).\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.741\n",
      "precision macro = 0.6959\n",
      "recall macro = 0.6783\n",
      "f1 score macro = 0.6849\n",
      "\n",
      "\n",
      "Model Ensemble Average:\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.741\n",
      "precision macro = 0.7121\n",
      "recall macro = 0.6616\n",
      "f1 score macro = 0.6818\n",
      "\n",
      "\n",
      "\n",
      "\u001b[4mBlendModel Model\u001b[0m:\n",
      "\n",
      "Scores :\n",
      "accuracy = 0.7368\n",
      "precision macro = 0.6857\n",
      "recall macro = 0.651\n",
      "f1 score macro = 0.6645\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "name_logs = 'best_logs'\n",
    "on_test_data = False\n",
    "autonlp.leader_predict(name_logs = name_logs, on_test_data = on_test_data, x = X_test, y=Y_test,\n",
    "                       doc_spacy_data_test = doc_spacy_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T14:40:07.064614Z",
     "iopub.status.busy": "2021-09-28T14:40:07.063918Z",
     "iopub.status.idle": "2021-09-28T14:40:07.069613Z",
     "shell.execute_reply": "2021-09-28T14:40:07.069066Z",
     "shell.execute_reply.started": "2021-09-28T13:43:01.101824Z"
    },
    "papermill": {
     "duration": 0.556232,
     "end_time": "2021-09-28T14:40:07.069788",
     "exception": false,
     "start_time": "2021-09-28T14:40:06.513556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Leaderboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>recall_macro_test</th>\n",
       "      <th>precision_macro_test</th>\n",
       "      <th>f1_macro_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tf-idf+SGD_Classifier_ADJ_NOUN_VERB_lem</td>\n",
       "      <td>0.7410</td>\n",
       "      <td>0.6616</td>\n",
       "      <td>0.7121</td>\n",
       "      <td>0.6818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tf+Logistic_Regression_ADJ_NOUN_VERB_lem</td>\n",
       "      <td>0.7420</td>\n",
       "      <td>0.6468</td>\n",
       "      <td>0.7025</td>\n",
       "      <td>0.6686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BlendModel</td>\n",
       "      <td>0.7368</td>\n",
       "      <td>0.6510</td>\n",
       "      <td>0.6857</td>\n",
       "      <td>0.6645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tf+Naive_Bayes_ADJ_NOUN_VERB_lem</td>\n",
       "      <td>0.7069</td>\n",
       "      <td>0.6477</td>\n",
       "      <td>0.6474</td>\n",
       "      <td>0.6468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       name  accuracy_test  recall_macro_test  \\\n",
       "2   tf-idf+SGD_Classifier_ADJ_NOUN_VERB_lem         0.7410             0.6616   \n",
       "0  tf+Logistic_Regression_ADJ_NOUN_VERB_lem         0.7420             0.6468   \n",
       "3                                BlendModel         0.7368             0.6510   \n",
       "1          tf+Naive_Bayes_ADJ_NOUN_VERB_lem         0.7069             0.6477   \n",
       "\n",
       "   precision_macro_test  f1_macro_test  \n",
       "2                0.7121         0.6818  \n",
       "0                0.7025         0.6686  \n",
       "3                0.6857         0.6645  \n",
       "1                0.6474         0.6468  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard_test = autonlp.get_leaderboard(sort_by=flags.sort_leaderboard, dataset='test', info_models=autonlp.info_models)\n",
    "print('\\nTest Leaderboard')\n",
    "leaderboard_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 272.362459,
   "end_time": "2021-09-28T14:40:10.021993",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-28T14:35:37.659534",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
